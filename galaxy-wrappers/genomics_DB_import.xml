<tool id="gatk4_GenomicsDBImport" name="GATK4 GenomicsDBImport" version="1.0.0">
    <description>- Import VCFs to GenomicsDB</description>
    <macros>
        <import>macros.xml</import>
    </macros>
    <expand macro="requirements" />
    <command detect_errors="exit_code">
<![CDATA[
        ##Fix to run on arm macbook
        export JAVA_HOME=/Users/benjaminbeer/Downloads/jdk-17.0.10.jdk/Contents/Home/bin &&
        export PATH=/Users/benjaminbeer/Downloads/jdk-17.0.10.jdk/Contents/Home/bin:\$PATH &&

        #if str($tool_params.tool_param_selector) == "advanced"
            #set $reference_provided = False
            #if str($FASTA_TYPE.FASTA_TYPE_SELECTOR) == "uploaded"
                #if str($FASTA) != "None":
                    ln -s "$FASTA" fasta.fa &&
                    #set $reference_provided = True
                #end if
            #else
                #set $fasta_file = $fasta_source.fasta_id.fields.path
                ln -s "$fasta_file" fasta.fa &&
                #set $reference_provided = True
            #end if
            #if $reference_provided
                samtools faidx fasta.fa &&
                gatk CreateSequenceDictionary -R fasta.fa -O fasta.dict &&
            #end if
        #end if

        #if str($GVCF_conditional.GVCF_selector) == "Individually"
            #for $i, $file in enumerate($variant_repeat):
                bgzip -c ${file.GVCF} > "${i}.gz" &&
                tabix -p vcf "${i}.gz" &&
            #end for
            gatk GenomicsDBImport
            #for $i, $file in enumerate($variant_repeat):
                --variant "${i}.gz" 
            #end for
        #else
            gatk GenomicsDBImport --sample-name-map "$variants"
        #end if

        #for $i, $interval in enumerate($intervals_repeat):
            --intervals "${interval.L}"
        #end for

        #if str($gatk_params.gatk_params_selector) == "advanced"
            ##Input Validation
            --read-validation-stringency "$read_validation_stringency"
            --disable-sequence-dictionary-validation "$disable_sequence_dictionary_validation"
            --lenient "$lenient"

            ##Genomic Intervals
            #for $i, $interval in enumerate($exclude_intervals_repeat):
                --exclude-intervals "${interval.XL}"
            #end for
            #if str($exclude_intervals_file) != "None"
                --exclude-intervals "$exclude_intervals_file"
            #end if
            --interval-exclusion-padding "$interval_exclusion_padding"
            --interval-set-rule "$interval_set_rule"

            ##Performance
            --use-jdk-deflater "$use_jdk_deflater"
            --use-jdk-inflater "$use_jdk_inflater"

            ##Macro Files
            #if str($gatk_config_file) != "None":
                --gatk-config-file "$gatk_config_file"
            #end if
            #if str($arguments_file) != "None":
                --arguments_file "$arguments_file"
            #end if
            #if str($sequence_dictionary) != "None":
                --sequence-dictionary "$sequence_dictionary"
            #end if
            #if str($read_index) != "None":
                --read-index "$read_index"
            #end if
        #end if


        #if str($tool_params.tool_param_selector) == "advanced"
            ##Inputs & Validation
            #if $reference_provided
                --reference "fasta.fa"
            #end if
            --validate-sample-name-map "$validate_sample_name_map"
            --disable-sequence-dictionary-validation "$disable_sequence_dictionary_validation"

            ##Genomic Intervals
            --interval-padding "$interval_padding"
            --interval-merging-rule "$interval_merging_rule"

            ##Penalties & Buffers
            --cloud-prefetch-buffer "$cloud_prefetch_buffer"
            #if $cloud_index_prefetch_buffer
                --cloud-index-prefetch-buffer "$cloud_index_prefetch_buffer"
            #end if

            ##Performance
            --batch-size "$batch_size"
            --gcs-max-retries "$gcs_max_retries"
            --genomicsdb-segment-size "$genomicsdb_segment_size"
            --genomicsdb-vcf-buffer-size "$genomicsdb_vcf_buffer_size"
            --max-num-intervals-to-import-in-parallel "$max_num_intervals_to_import_in_parallel"
            --reader-threads "$reader_threads"
            --consolidate "$consolidate"
            --disable-bam-index-caching "$disable_bam_index_caching"

            ##Outputs
            --sites-only-vcf-output "$sites_only_vcf_output"
            #if $gcs_project_for_requester_pays
                --gcs-project-for-requester-pays "$gcs_project_for_requester_pays"
            #end if
        #end if
        --genomicsdb-workspace-path genomics_db_out &&

        zip -r out.zip genomics_db_out &&
        cp out.zip "$output1"
    ]]>
    </command>
    <inputs>
        <conditional name="GVCF_conditional">
            <param name="GVCF_selector" type="select" label="Variants" >
                <option value="Individually" selected="True">Individually</option>
                <option value="Map">Map</option>
            </param>
        <when value="Individually">
            <repeat argument="--variant" name="variant_repeat" title="GVCF files to be imported to GenomicsDB" help="Each file must contain data for only a single sample." default="1" >
                <param name="GVCF" type="data" format="vcf" />
            </repeat>      
        </when>
        <when value="Map">
          <param type="data" name="variants" format="sample_map" label="Map of GVCFs" />
        </when>
      </conditional>    
      <repeat argument="--intervals" name="intervals_repeat" title="Genomic interval over which to operate" help="-L" default="1">
            <param name="L" type="text" value=""/>
        </repeat>        

      <expand macro="gatk_param_type_conditional" />


      <conditional name ="tool_params">
      <param name="tool_param_selector" type="select" label="Basic or Advanced Tool options">
      <option value="basic" selected="True">Basic</option>
      <option value="advanced">Advanced</option>
      </param>
      <when value = "basic">
          <!--Do nothing-->
      </when>
      <when value="advanced">
        <section name="Inputs &amp; Validation">
          <conditional name="FASTA_TYPE">
            <param name="FASTA_TYPE_SELECTOR" type="select" label="Number of files containing known sites" >
                <option value="uploaded" selected="True">Uploaded</option>
                <option value="galaxy">Galaxy</option>
            </param>
            <when value="uploaded">
                <param type="data" name="FASTA" argument="--reference" format="fasta" label="Reference file"/>
            </when>
            <when value="galaxy">
              <param argument="--reference" type="select" label="Select reference genome" help="If your genome of interest is not listed, contact the Galaxy team" optional="True">
                  <options from_data_table="fasta_indexes" />
              </param>
            </when>
          </conditional>
          <param type="boolean" argument="--validate-sample-name-map" label="Enable checks on the sampleNameMap file" checked="False" />
          <param type="boolean" argument="--disable-sequence-dictionary-validation" label="Validate inputs with sequence dictionaries" checked="True" help="Disable at your own risk!" />
        </section>
        <section name="Genomic Intervals">
            <param type="integer" argument="--interval-padding" label="Amount of padding for each interval (bp)" value="0" help="For example, -L 1:100 with a padding value of 20 would turn into -L 1:80-120."/>
            <param type="select" argument="--interval-merging-rule" label="Rule for merging abutting intervals">
                <option value="ALL" selected="True">ALL</option>
                <option value="OVERLAPPING_ONLY">OVERLAPPING_ONLY</option>
            </param>
        </section>
        <section name="Penalties &amp; Buffers">
            <param type="integer" argument="--cloud-prefetch-buffer" label="Size of the cloud-only prefetch buffer (in MB)" value="40" help="0 to disable." />
            <param type="integer" argument="--cloud-index-prefetch-buffer" label="Size of the cloud-only prefetch buffer (in MB)" optional="True" help="Defaults to cloudPrefetchBuffer" />
        </section>
        <section name="Performance">
            <param type="integer" argument="--batch-size" label="Number of samples that are open at once" value="0" />
            <param type="integer" argument="--gcs-max-retries" value="20" label="Number of times to attempt to re-initiate connection to GCS bucket channel" />
            <!-- Check if segment/buffer should be long -->
            <param type="integer" argument="--genomicsdb-segment-size" label="Buffer size allocated for GenomicsDB (bytes)" value="1048576" />
            <param type="integer" argument="--genomicsdb-vcf-buffer-size" label="Buffer size for storing variant contexts (bytes)" value="16384" />
            <param type="integer" argument="--max-num-intervals-to-import-in-parallel" label="Max number of intervals to import in parallel" value="1" />
            <param type="integer" argument="--reader-threads" label="Number of simultaneous threads to use when opening VCFs in batches" value="1" />
            <param type="boolean" argument="--consolidate" label="Merge all fragments into one" checked="False" />
            <param type="boolean" argument="--disable-bam-index-caching" label="Cache bam indexes (reduces memory requirements)" checked="True" />
        </section>
        <section name="Outputs amp; Payment">
            <param type="boolean" argument="--sites-only-vcf-output" label="Don't emit genotype fields when writing vcf file" checked="False" />
            <param type="text" argument="--gcs-project-for-requester-pays" label="Project to bill when accessing requester pays buckets" optional="True" />
        </section>
        </when>
    </conditional>

          <!-- 
        Omitted:
        -overwrite-existing-genomicsdb-workspace

        -create-output-bam-index, 
        -create-output-bam-md5, 
        -preserve-qscores-less-than,
        -create-output-variant-index, 
        -create-output-variant-md5 
        -QUIET
        -seconds-between-progress-updates
        -TMP_DIR
        -->

    </inputs>
    <outputs>
        <data name="output1" format="zip" label="Compressed Database"/>
    </outputs>

    <tests>
    </tests>

    <help>
      **What it does**

      Import single-sample GVCFs into GenomicsDB before joint genotyping.
      The GATK4 Best Practice Workflow for SNP and Indel calling uses GenomicsDBImport to merge GVCFs from multiple samples. GenomicsDBImport offers the same functionality as CombineGVCFs and initially came from the Intel-Broad Center for Genomics. The datastore transposes sample-centric variant information across genomic loci to make data more accessible to tools.

      To query the contents of the GenomicsDB datastore, use SelectVariants. See Tutorial#11813 to get started.

      Details on GenomicsDB are at https://github.com/GenomicsDB/GenomicsDB/wiki. In brief, GenomicsDB utilises a data storage system optimized for storing/querying sparse arrays. Genomics data is typically sparse in that each sample has few variants with respect to the entire reference genome. GenomicsDB contains specialized code for genomics applications, such as VCF parsing and INFO field annotation calculation.

      https://gatk.broadinstitute.org/hc/en-us/articles/5358869876891-GenomicsDBImport

    </help>

</tool>